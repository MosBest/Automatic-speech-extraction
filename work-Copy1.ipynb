{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从远程数据库中读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import jieba\n",
    "from collections import Counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(string):\n",
    "    return ' '.join(jieba.cut(string))\n",
    "\n",
    "def token(string):\n",
    "    string = re.findall('[\\d|\\w]+', string)\n",
    "    return ' '.join(string)\n",
    "\n",
    "def deal(string):\n",
    "    string = token(string)\n",
    "    return cut(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.444 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'大家 好   我 在 学习 NLP'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = '大家好, 我在学习NLP'\n",
    "deal(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pymysql.connect(\"cdb-q1mnsxjb.gz.tencentcdb.com\", \"root\", \"A1@2019@me\", \"news_chinese\", port=10102)\n",
    "cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"select count(content) from sqlResult_1558435\"\"\"\n",
    "try:\n",
    "    cursor.execute(sql)\n",
    "except:\n",
    "    print(\"Error\")\n",
    "length_corpus = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.5074779987335205\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "with open('news.txt', 'a') as f:\n",
    "    for i in range(0,length_corpus[0][0], 10):\n",
    "        sql = \"\"\"select content from sqlResult_1558435 where id>={} and id < {}\"\"\".format(i, i+10)\n",
    "        try:\n",
    "            cursor.execute(sql)\n",
    "        except:\n",
    "            print(\"Error\")\n",
    "\n",
    "        news = cursor.fetchall()\n",
    "\n",
    "        for j in range(len(news)):\n",
    "            data = news[j][0]\n",
    "            text = deal(data)\n",
    "            f.write(text + '\\n')\n",
    "        break\n",
    "print(time.time() - start)\n",
    "cursor.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "news_word2ve = Word2Vec(LineSentence('news.txt'), size = 35, workers=8)\n",
    "#news_word2ve.most_similar('说')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 维基百科和新闻语料库制作的词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/zhaodao/下载/text/'\n",
    "def get_data(path):\n",
    "    dir_name = os.listdir(path)\n",
    "    STRING = []\n",
    "    for name in dir_name:\n",
    "        print(\"name\", name)\n",
    "        one_path = os.path.join(path, name)\n",
    "        all_ = os.listdir(one_path)\n",
    "        for file in all_:\n",
    "            print(\"file\", file)\n",
    "            data = open(os.path.join(one_path, file))\n",
    "            yield data.readlines()\n",
    "\n",
    "data = get_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file wiki_28\n",
      "file wiki_33\n",
      "file wiki_14\n",
      "file wiki_88\n",
      "file wiki_06\n",
      "file wiki_01\n",
      "file wiki_62\n",
      "file wiki_10\n",
      "file wiki_73\n",
      "file wiki_34\n",
      "file wiki_25\n",
      "file wiki_36\n",
      "file wiki_08\n",
      "file wiki_07\n",
      "file wiki_85\n",
      "file wiki_82\n",
      "file wiki_45\n",
      "file wiki_67\n"
     ]
    }
   ],
   "source": [
    "with open('news-sentences-xut.txt', 'a') as f:\n",
    "    while True:\n",
    "        try:\n",
    "            b = next(data)\n",
    "            text = [deal(string) for string in b if string!='\\n']\n",
    "            for n in text:\n",
    "                f.write(n + '\\n')\n",
    "        except:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用搜索树＋动态规划得到和“说”相近的词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用NER, Dependency Parsing获得是谁说了话，说了什么话"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 句子结束"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 制作网页呈现内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 服务器部署"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
